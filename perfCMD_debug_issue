cp config93GB.json config.json
numactl -l -N 0 ./skyriver  -debugDirectory=n1022/logs_0


/home/regression/tools/mutilateGA
./mutilate -s 10.0.0.22 -d 1 -c 128 -T 12 -t 600 -r 10000 -V 1000000 -K 13 -u 1.000000 --noload --affinity

iostat or bmon


/proc/sys/net/ipv4$ cat tcp_rmem 
4096	87380	6291456

/proc/sys/net/core$ cat rmem_default 
212992
regression@n1022:/proc/sys/net/core$ cat rmem_max 
212992
regression@n1022:/proc/sys/net/core$ cat wmem_default 
212992
regression@n1022:/proc/sys/net/core$ cat wmem_max 
212992
regression@n1022:/proc/sys/net/core$ cat optmem_max 
20480
regression@n1022:/proc/sys/net/core$ cat netdev_max_backlog 
1000

sysctl -a | grep mem
net.core.optmem_max = 20480
net.core.rmem_default = 212992
net.core.rmem_max = 212992
net.core.wmem_default = 212992
net.core.wmem_max = 212992

net.ipv4.tcp_mem = 6189357	8252476	12378714
net.ipv4.tcp_rmem = 4096	87380	6291456
net.ipv4.tcp_wmem = 4096	16384	4194304
net.ipv4.udp_mem = 12378714	16504952	24757428
net.ipv4.udp_rmem_min = 4096
net.ipv4.udp_wmem_min = 4096

net.ipv4.tcp_no_metrics_save = 0

$ sudo sysctl -w net.ipv4.tcp_rmem='4096 87380 32765'


# test env:
server used: 33 (skyriver), 32(mutilate), 26(mutilate)

# Test commands:

# skyriver
~/Skyriver_Binary/Kessel1.0rc3$ numactl -l -N 0 ./skyriver  -debugDirectory=n1033/logs_0

# iperf server
iperf -s

# iperf client
iperf -c 10.0.0.22 -i 5 -t 10 -l 1M

# perf tool watchers on n1033
iostat 2
bmon

# 1 or 2 mutilate instances:
numactl --localalloc --cpunodebind=0 ./mutilate -s 10.0.0.33 -d 1 -c 128 -T 12 -t 600 -r 10000 -V 1000000 -K 13 -u 1.000000 --noload --affinity
numactl --localalloc --cpunodebind=1 ./mutilate -s 10.0.0.33 -d 1 -c 128 -T 12 -t 600 -r 10000 -V 1000000 -K 13 -u 1.000000 --noload --affinity

 # result: 1 instance
nvme1n1        8657.50    513328.00    533248.00    1026656    1066496
nvme0n1        8791.00    396462.00    665216.00     792924    1330432
  p27p2                        │   1.15GiB 813.63K     │   4.76MiB  75.36K

# result: 2 instances from 2 servers
nvme1n1        2183.50    131924.00    131072.00     263848     262144
nvme0n1        2122.50     31564.00    223360.00      63128     446720
  p27p2                        │ 390.12MiB 270.40K     │   6.00MiB  82.21K

# result: 2 instances from 1 server
numactl --localalloc --cpunodebind=1
nvme1n1        9997.50    604292.00    620544.00    1208584    1241088
nvme0n1        9559.00    664528.00    497984.00    1329056     995968
  p27p2                        │   1.15GiB 813.14K     │   6.55MiB 103.91K

# after 10-20 seconds, numbers dropped and varies
nvme1n1        5300.50    346834.00    307584.00     693668     615168
nvme0n1        4859.50    348594.00    250304.00     697188     500608
  p27p2                        │ 560.96MiB 388.79K     │   7.08MiB  99.95K
nvme1n1        3217.50    132024.00    262144.00     264048     524288
nvme0n1        2686.50    262988.00     64320.00     525976     128640
  p27p2                        │ 479.50MiB 332.34K     │   5.82MiB  82.69K

# result: 1 instance and 1 iperf
nvme1n1        3049.00    244454.00    131072.00     488908     262144
nvme0n1        2185.50    131958.00    131072.00     263916     262144
  p27p2                        │   1.05GiB 746.16K     │   6.59MiB  90.38K

net.ipv4.tcp_mem = 6188841	8251789	12377682
net.ipv4.tcp_rmem = 4096	87380	6291456
net.ipv4.tcp_wmem = 4096	16384	4194304
net.ipv4.udp_mem = 12377682	16503579	24755364
net.ipv4.udp_rmem_min = 4096
net.ipv4.udp_wmem_min = 4096
net.core.optmem_max = 20480
net.core.rmem_default = 212992
net.core.rmem_max = 212992
net.core.wmem_default = 212992
net.core.wmem_max = 212992
net.ipv4.igmp_max_memberships = 20

net.ipv4.tcp_allowed_congestion_control = cubic reno
net.ipv4.tcp_available_congestion_control = cubic reno
net.ipv4.tcp_congestion_control = cubic
net.ipv4.tcp_mtu_probing = 0
net.core.default_qdisc = pfifo_fast


sudo sysctl -w net.core.rmem_max=67108864
sudo sysctl -w net.core.wmem_max=67108864

# allow testing with buffers up to 64MB 
net.core.rmem_max = 67108864 
net.core.wmem_max = 67108864 
# increase Linux autotuning TCP buffer limit to 32MB
net.ipv4.tcp_rmem = 4096 87380 33554432
net.ipv4.tcp_wmem = 4096 65536 33554432
# recommended default congestion control is htcp 
net.ipv4.tcp_congestion_control=htcp
# recommended for hosts with jumbo frames enabled
net.ipv4.tcp_mtu_probing=1
# recommended for CentOS7/Debian8 hosts
net.core.default_qdisc = fq
